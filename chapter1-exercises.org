[[https://mitpress.mit.edu/sicp/full-text/book/book-Z-H-11.html#%25_sec_1.2][Taken from here]]

Please note: I've lifted most of these exercises mostly verbatim but
added code where necessary and made more language more succinct in
others.  These exercises are not mine, they are the authors of SICP.
The solutions are mine unless otherwise cited.
* Section 1.2.4
[[info:sicp#1-2-4][Section 1.2.4]]
** Exercise 1.17
*** Problem Statement
The following multiplication procedure (in which it is assumed that
our language can only add, not multiply) is analogous to the =expt=
procedure:
#+BEGIN_SRC scheme
    (define (* a b)
    (if (= b 0)
        0
        (+ a (* a (- b 1)))))
#+END_SRC
This algorithm takes a number of steps that is linear in =b=.  Now
suppose we include, together with addition, operations =double=, which
doubles and integer, and =halve= which divides an (even) integer
by 2.  Using these design a multiplication procedure analogous to
=fast-expt= that uses a logarithmic number of steps.

*** Solution
#+BEGIN_SRC scheme
  (define (even? n)
    (= (remainder n 2) 0))
  (define (double x)
    (+ x x))
  (define (halve x)
    (/ x 2))
  (define (fast-* a b)
    (cond ((= b 2) (double a))
          ((even? b) (double (fast-* a (halve b))))
          (else (+ a (fast-* a (- b 1))))))
  (and (= (fast-* 12 12) 144)
       (= (fast-* 7 3)   21)
       (= (fast-* 10 10) 100))
#+END_SRC

** Exercise 1.18
*** Problem Statement
Using the results of exercise 1.16 and 1.17, devise a procedure that
generates an iterative process for multiplying two integers in terms
of adding, doubling, and halving and uses a logarithmic number of
steps.
*** Solution
#+BEGIN_SRC scheme
    (define (fast-* a b)
      (iter-* a b 1)
    (define (iter-* a b result)
      (cond ((= b 2) (double result))
            ((even? b) (iter-* a (halve b) (double result)))
            (else (iter-* a (- b 1) (+ result a)))))
  (and (= (fast-* 12 12) 144)
       (= (fast-* 7 3)   21)
       (= (fast-* 10 10) 100))
#+END_SRC
* Section 1.2.5
[[info:sicp#1-2-5][Section 1.2.5]]
** Exercise 1.20
*** Problem
Consider the iterative =gcd= procedure:
#+BEGIN_SRC scheme
  (define (gcd a b)
    (if (= b 0)
        a
        (gcd b (remainder a b))))
#+END_SRC
Suppose we were to interpret this procedure using normal-order
evaluation (discussed in section 1.1.5). Using the substitution
method illustrate the process generated in evaluating =(gcd 206 40)=
and indicate the =remainder= operations that are actually
performed. How many =remainder= operations are actually performed in
the normal-order evaluation of =(gcd 206 40)=? In applicative-order
evaluation?
*** Solution
Reminder: 
- *Normal order* means expand function calls until only primatives
  remain and then evaluate them to arrive at the final result
- *Applicative order* means evaluate the arguments of function calls
  immediately and then call remaining functions until final result
**** Normal order
http://community.schemewiki.org/?sicp-ex-1.20
#+BEGIN_SRC example
  (gcd 206 40)
  (if (= 40 0) ... (gcd 40 (remainder 206 40)))
  (if (= 6 0) ... (gcd (remainder 206 40) (remainder 40 (remainder 206 40)))) ; 1 remainder call
  (if (= 4 0) ... (gcd (remainder 40 (remainder 206 40)) (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))))  ; 2 remainder calls
  (if (= 2 0) ... (gcd (remainder (remainder 206 40) (remainder 40 (remainder 206 40))) ; 4 remainder calls
                       (remainder (remainder 40 (remainder 206 40)) (remainder (remainder 206 40) (remainder 40 (remainder 206 40))))))
  (if (= 0 0) (remainder (remainder 206 40) (remainder 40 (remainder 206 40)))) ; 7 remainder calls
  (remainder (remainder 206 40) (remainder 40 (remainder 206 40))) 
  2 ;4 remainder calls
#+END_SRC
Total calls to remainder: 18
**** Applicative Order
#+BEGIN_EXAMPLE
(gcd 206 40)
(gcd 40 (remainder 206 40))
(gcd 40 6)
(gcd 6 (remainder 40 6))
(gcd 6 4)
(gcd 4 (remainder 6 4))
(gcd 4 2)
(gcd 2 (remainder 4 2))
(gcd 2 0)
2
#+END_EXAMPLE
Total calls to remainder: 4
* Section 1.2.6
[[info:sicp#1-2-6][Section 1.2.6]]
** Exercise 1.22 
*** Problem
The following =timed-prime-test= procedure when called with integer
=n=, prints =n= and checks to see if =n= is prime. If so, it prints
three asterisks followed by the amount of time used in performing the
test.  Timing is done with the primitive =current-milliseconds=.
#+BEGIN_SRC scheme
  (define (square x)
    (* x x))

  (define (smallest-divisor n)
    (find-divisor n 2))
  (define (find-divisor n test-divisor)
    (cond ((> (square test-divisor) n) n)
          ((divides? test-divisor n) test-divisor)
          (else (find-divisor n (+ test-divisor 1)))))
  (define (divides? a b)
    (= (remainder b a) 0))
  (define (prime? n)
    (= n (smallest-divisor n)))
  
  (define (timed-prime-test n)
    (display n)
    (start-prime-test n (current-milliseconds))
    (newline))
  (define (start-prime-test n start-time)
    (when (prime? n)
        (report-prime (- (current-milliseconds) start-time))))
  (define (report-prime elapsed-time)
    (display " *** ")
    (display elapsed-time))

#+END_SRC
Using this procedure, write a =search-for-primes= that checks the
primality of consecutive odd integers in a specified range.  Use your
procedure to find the smallest 3 primes larger than:
- 1000
- 10,000
- 1,000,000
Is the timing information consistent with $O(\sqrt{n})$ steps? Is
this compatible with the idea that run time is proportional to the
number of steps required for computation? 
*** Solution
I originally wrote this with a let, which I think is cheating, so I
cheated worse and referenced:
http://www.billthelizard.com/2010/02/sicp-exercise-122-timed-prime-test.html
#+BEGIN_SRC scheme
(define (search-for-primes a b)
  (if (even? a)
      (search-for-primes (+ a 1) b)
      (when (< a b)
        (timed-prime-test a)
        (search-for-primes (+ a 1) b))))
#+END_SRC
|            Prime | Time (ms) | Ratio |
|------------------+-----------+-------|
|    1000000000061 |       117 |       |
|    1000000000063 |       115 |       |
|   10000000000037 |       378 | 0.313 |
|   10000000000051 |       367 |       |
|   10000000000099 |       367 |       |
|  100000000000031 |      1154 |  0.32 |
|  100000000000067 |      1146 |       |
|  100000000000097 |      1151 |       |
| 1000000000000037 |      3605 | 0.318 |
| 1000000000000091 |      3607 |       |
| 1000000000000159 |      3640 |       |
|------------------+-----------+-------|
Expect $T(n) \propto \sqrt{n}$, therefore:
$$
\frac{T(10^n)}{T(10^{n+1})}=\frac{1}{\sqrt{10}} = 0.3162
$$
The experimental data backs up the expectation that the number of
steps required is proportional to the run time.
** Exercise 1.24 
*** Problem
Modify the =timed-prime-test= procedure from Exercise 1.22 to use
=fast-prime?= (the Fermat method), and test the 12 primes you found
in that exercise. Does your data agree with the expected $O(\log n)$
growth? 
*** Solution
#+BEGIN_SRC scheme
  (require (lib "27.ss" "srfi"))
  (define (square x)
    (* x x))
  (define (expmod base exp m)
    (cond ((= exp 0) 1)
          ((even? exp)
           (remainder (square (expmod base (/ exp 2) m))
                      m))
          (else
           (remainder (* base (expmod base (- exp 1) m))
                      m))))
  (define (timed-prime-test n)
    (display n)
    (start-prime-test n (current-milliseconds))
    (newline))
  (define (start-prime-test n start-time)
    (when (fast-prime? n 10000)
        (report-prime (- (current-milliseconds) start-time))))
  (define (report-prime elapsed-time)
    (display " *** ")
    (display elapsed-time))
  
  (define (fermat-test n)
    (define (try-it a)
      (= (expmod a n n) a))
    (try-it (+ 1 (random-integer (- n 1)))))
  (define (fast-prime? n times)
    (cond ((= times 0) true)
          ((fermat-test n) (fast-prime? n (- times 1)))
          (else false)))
(timed-prime-test   1000000000061)
(timed-prime-test   1000000000063)
(timed-prime-test  10000000000037)
(timed-prime-test  10000000000051)
(timed-prime-test  10000000000099)
(timed-prime-test 100000000000031)
(timed-prime-test 100000000000067)
(timed-prime-test 100000000000097)
(timed-prime-test 1000000000000037)
(timed-prime-test 1000000000000091)
(timed-prime-test 1000000000000159)
#+END_SRC
Results:
(times cranked up to 1000 to get reasonable numbers)
|------------------+-----------+-----+-----------------+-------------|
|            Prime | Time (ms) | Avg | Ratio (n/(n-1)) | Expected    |
|------------------+-----------+-----+-----------------+-------------|
|    1000000000061 |       324 |     |                 |             |
|    1000000000063 |       262 | 293 |                 |             |
|   10000000000037 |       266 |     |                 |             |
|   10000000000051 |       270 |     |                 |             |
|   10000000000099 |       271 | 269 |            0.91 | 12/13=0.923 |
|  100000000000031 |       307 |     |                 |             |
|  100000000000067 |       298 |     |                 |             |
|  100000000000097 |       298 | 301 |            0.89 | 13/14=0.928 |
| 1000000000000037 |       324 |     |                 |             |
| 1000000000000091 |       335 | 330 |            0.91 | 14/15=0.933 |
|------------------+-----------+-----+-----------------+-------------|
The data matches (roughly) with expected answer.
** Exercise 1.27
*** Problem
Demonstrate that the Carmichael numbers really do fool the Fermat
test.  Write a procedure that takes an integer $n$ and tests whether
$a^n$ is congruent to $a$ modulo $n$ for every $a<n$.  Try the
procedure on the given Carmichael numbers. 
*** Solution
We need expmod
#+BEGIN_SRC scheme
  (define (square x) (* x x))
  (define (expmod base exp m)
    (cond ((= exp 0) 1)
          ((even? exp)
           (remainder (square (expmod base (/ exp 2) m))
                      m))
          (else
           (remainder (* base (expmod base (- exp 1) m))
                      m))))
  (define (carmichael? n)
    (define (cm-test n a)
      (cond ((= a n) #t)
            ((= (expmod a n n) a) (cm-test n (+ a 1))) 
            (else #f)))
    (cm-test n 0))
  (map carmichael? '(561 1105 1729 2465 2821 6601))
#+END_SRC
* Section 1.3.1
[[info:sicp#1-3-1][Section 1.3.1]]
** Exercise 1.30 
*** Problem 
The =sum= procedure generates a linear recursion.
#+BEGIN_SRC scheme
  (define (sum term a next b)
    (if (> a b)
        0
        (+ (term a) (sum term (next a) next b))))
#+END_SRC
The procedure can be re-written so that the sum is performed
iteratively. Show how to do this by filling in the missing
expressions in the following definition:
#+BEGIN_SRC scheme
  (define (sum term a next b)
    (define (iter a result)
      (if ??
          ??
          (iter ?? ??)))
    (iter ?? ??))
#+END_SRC
*** Solution
Terminating the sum is the same as before, =a= gets incremented until
it overtakes =b= and the sum stops and returns the result, the
iterative part comes from the second argument in the call to =iter=,
this will hold the result.  Then the only remaining bit is how to
start the =iter= procedure:
#+BEGIN_SRC scheme
(define (sum term a next b)
    (define (iter a result)
      (if (> a b)
          result
          (iter (next a) (+ (term a) result))))
    (iter a 0))
(define (cube x)
  (* x x x))
(define (inc n) (+ n 1))
(define (sum-cubes a b)
  (sum cube a inc b))
(= (sum-cubes 1 10) 3025)
#+END_SRC
** Exercise 1.31
*** Problem
a. The =sum= procedure is only the simplest of a vast number of
similar abstractions that can be captured as higher-order
procedures.  Write an analogous procedure =product= that returns the
product of values of a function at points over a given range. Show
how to define =factorial= in terms of =product=. Also use =product=
to compute approximations to \pi using the formula:
$$
\frac{\pi}{4} = \frac{2\cdot4\cdot4\cdot6\cdot6\cdot8\cdots}{3\cdot3\cdot5\cdot5\cdot7\cdot7\cdots}
$$
b. If your procedure generates a recursive process, write one that
generates an iterative process, or vice versa.
*** Solution

#+BEGIN_SRC scheme
  (define (product term a next b)
    (if (> a b)
        1
        (* (term a) (product term (next a) next b))))
#+END_SRC
This generates the recursive version using the same signature as
=sum=, =factorial= then becomes:
#+BEGIN_SRC scheme
  (define (inc n) (+ n 1))
  (define (id x) x)
  (define (factorial n)
    (product id 1 inc n))
#+END_SRC
Calculating \pi:
#+BEGIN_SRC scheme
  (define (inc n) (+ n 1))
  (define (wallis-term n)
    (/ (square (* 2 n))
       (* (- (* 2 n) 1) (+ (* 2 n) 1))))
  (define (pi n)
    (* 2 (product wallis-term 1 inc n)))
(+ 0.0 (pi 10000))
#+END_SRC
My product is recursive, so here's the iterative version:
#+BEGIN_SRC scheme
  (define (product term a next b)
      (define (iter a result)
        (if (> a b)
            result
            (iter (next a) (* (term a) result))))
      (iter a 1))
#+END_SRC
* Section 1.3.2
[[info:sicp#1-3-2][Section 1.3.2]]
** Exercise 1.34 
*** Problem
Suppose we define the procedure:
#+BEGIN_SRC scheme
(define (f g)
  (g 2))
#+END_SRC
Then we have:
#+BEGIN_EXAMPLE
(f square)
4
(f (lambda (z) (* z (+ z 1))))
6
#+END_EXAMPLE
What happens if we (perversely) as the interpreter to evaluate the
combination =(f f)=? Explain.
*** Solution
Using applicative order evaluation:
#+BEGIN_EXAMPLE
(f f)
(f 2)
(2 2)
; ERROR no function '2'
#+END_EXAMPLE
* Section 1.3.4
[[info:sicp#1-3-4][Section 1.3.4]]
** Exercise 1.40 
*** Problem
Define a procedure =cubic= that can be used together with
=newtons-method= procedure in expressions of the form:
#+BEGIN_EXAMPLE
(newtons-method (cubic a b c) 1)
#+END_EXAMPLE
to approximate zeroes of the cubic $x^3 + ax^2 + bx +c$.
*** Solution
First we need the code that performs Newton's method:
#+BEGIN_SRC scheme
  (define dx 1e-5)
  (define (deriv g)
    (lambda (x)
      (/ (- (g (+ x dx) (g x)))
         dx)))
  (define tolerance 1e-5)
  (define (fixed-point f first-guess)
    (define (close-enough? v1 v2)
      (< (abs (- v1 v2)) tolerance))
    (define (try guess)
      (let ((next (f guess)))
        (if (close-enough? guess next)
            next
            (try next))))
    (try first-guess))
  (define (newton-transform g)
    (lambda (x)
      (- x (/ (g x) ((deriv g) x)))))
  (define (newtons-method g guess)
    (fixed-point (newton-transform g) guess))
#+END_SRC
Now we just need a procedure which returns a procedure representing
the cubic polynomial in question:
#+BEGIN_SRC scheme
  (define (cube x)
    (* x x x))
  (define (square x)
    (* x x))
  (define (cubic a b c)
    (lambda (x)
      (+ (cube x) (* a (square x)) (* b x) c)))
#+END_SRC
** Exercise 1.41 
*** Problem
Define a procedure =double= that takes a procedure of one argument as
argument and returns a procedure that applies the original procedure
twice. For example, if =inc= is a procedure that adds 1 to its
argument, then =(double inc)= should be a procedure that adds 2.
What is the value returned by
#+BEGIN_EXAMPLE
(((double (double double)) inc) 5)
#+END_EXAMPLE
*** Solution
Here's the procedure:
#+BEGIN_SRC scheme
  (define (double proc)
    (lambda (x)
      (proc (proc x))))
#+END_SRC
#+BEGIN_EXAMPLE
(((double (double double)) inc) 5)
#+END_EXAMPLE
This can be expanded (or fed to the interpreter) to give =21=
** Exercise 1.42
*** Problem
Let $f$ and $g$ be two one-argument functions. The /composition/ of
$f$ after $g$ is defined to be the function $x\rightarrow
f(g(x))$. Define a procedure =compose= that implements
composition. For example, if =inc= is a procedure that adds 1 to its
argument,
#+BEGIN_EXAMPLE
((compose square inc) 6)
49
#+END_EXAMPLE
*** Solution
Here's the procedure:
#+BEGIN_SRC scheme
  (define (compose f g)
    (lambda (x)
      (f (g x))))
#+END_SRC
** Exercise 1.43 
*** Problem
If $f$ is a numerical function and $n$ is a positive integer, then we
can form the $n$th repeated application of $f$, which is defined as
the function whose value at $x$ is $f(f(\ldots (f(x)) \ldots)). For
example, if $f$ is the function $x\rightarrow x+1$, then the $n$th
repeated application of $f$ is the function $x\rightarrow x+n$. If
$f$ is the operation of squaring a number then the $n$th repeated
application of $f$ raises its argument to the $2^n$th power. Write a
procedure that takes as inputs a procedure that computes $f$ and a
positive integer $n$ and returns the procedure that computes the
$n$th repeated application of $f$. Example:
#+BEGIN_EXAMPLE
((repeated square 2) 5)
625
#+END_EXAMPLE
*** Solution
#+BEGIN_SRC scheme
    (define (repeated f n)
      (if (= n 1)
          f
          (compose f (repeated f (- n 1)))))
#+END_SRC
** Exercise 1.45 
http://www.billthelizard.com/2010/08/sicp-145-computing-nth-roots.html
*** Problem
Determine the number of "average damps" required to compute $n$th
roots as a fixed-point search.  Use this to implement a simple
procedure for computing $n$th roots using =fixed-point=,
=average-damp=, and the =repeated= procedure from Ex. 1.43.
*** Solution
First the required code:
#+BEGIN_SRC scheme
    (define tolerance 1e-5)
    (define (average a b)
      (/ (+ a b)
         2))
    (define (average-damp f)
      (lambda (x) (average x (f x))))
    (define (fixed-point f first-guess)
      (define (close-enough? v1 v2)
        (< (abs (- v1 v2)) tolerance))
      (define (try guess)
        (let ((next (f guess)))
          (if (close-enough? guess next)
              next
              (try next))))
      (try first-guess))
  (define (expt b n)
    (cond ((= n 0) 1)
          ((even? n) (square (expt b (/ n 2))))
          (else (* b (expt b (- n 1))))))
#+END_SRC
Now, the procedure:

#+BEGIN_SRC scheme
(define (nth-root x n)
  (fixed-point ((repeated average-damp 2)
                (lambda (y) (/ x (expt y (- n 1)))))
               1.0))
#+END_SRC
|----------+-------|
| Repeated | Max n |
|----------+-------|
|        1 |     3 |
|        2 |     6 |
|        3 |       |
** Exercise 1.46
